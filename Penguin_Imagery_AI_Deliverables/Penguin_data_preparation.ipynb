{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226cf3f1",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821cdea",
   "metadata": {
    "id": "f821cdea"
   },
   "source": [
    "\n",
    "## Emperor Penguin Study - Data Preparation\n",
    "\n",
    "Data for the penguin study is stored in a directory structure on the file system. Penguin colonies are the highest directory, then classification studies by date and image catalog id directories, which contain the study shapefiles and signature file.\n",
    "\n",
    "This notebook navigates the project directories and creates useful data structures and image tiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uPKe0s2c-ZR8",
   "metadata": {
    "id": "uPKe0s2c-ZR8"
   },
   "source": [
    "<br><br><br>\n",
    "## SECTION: Initialize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b12cb",
   "metadata": {
    "id": "c70b12cb"
   },
   "source": [
    "#### Naming conventions\n",
    "\n",
    "##### colony - the name of a penguin colony as used in the project directory structure. Colony names do not have spaces and the individual parts are capitalized. ie 'Amanda Bay' becomes 'AmandaBay'\n",
    "\n",
    "##### prjShapeCatalog (project shapefile catalog) - a list of all of the shapefiles found in the project directory structure. Only the file with the '.shp' suffix is in this list. Each entry contains the entire path to the file.\n",
    "\n",
    "##### imgCatalog (images catalog) - a list containing the entire path to every image file (.tif) on the mounted external drives.\n",
    "\n",
    "##### prjCatalog (projects catalog) - a list of individual project directories found in the project directory structure. These directories are named by concatenating colony name, year, month day (optional), and catalog id(s) separated by \"_\". ie 'KloaPoint_2013_1010010011FFD500'\n",
    "\n",
    "##### Projects data structure - a structured list of [colony name, year, month day, [catalog ids], project directory name]\n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JuPkotgo_CfC",
   "metadata": {
    "id": "JuPkotgo_CfC"
   },
   "source": [
    "#### If needed, install libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zaRP2ANM_Joj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zaRP2ANM_Joj",
    "outputId": "41fc20e8-3e88-47a6-d5be-797a6d76e83d"
   },
   "outputs": [],
   "source": [
    "!pip install rasterio geopandas fiona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j9FnCNtS-oz8",
   "metadata": {
    "id": "j9FnCNtS-oz8"
   },
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62555ed3",
   "metadata": {
    "id": "62555ed3"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Import needed libraries\n",
    "#\n",
    "\n",
    "import rasterio as rio\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "# Enable fiona driver\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6vE-rCcCAI21",
   "metadata": {
    "id": "6vE-rCcCAI21"
   },
   "source": [
    "#### Constants and search paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49120c4",
   "metadata": {
    "id": "d49120c4"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Constants\n",
    "#\n",
    "\n",
    "# Different tile sizes, used for buffering...\n",
    "NONE = 0\n",
    "TILE16 = 1\n",
    "TILE32 = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e264f60",
   "metadata": {
    "id": "5e264f60"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Set the search paths...\n",
    "#\n",
    "\n",
    "mount_dir = \"/media\"\n",
    "proj_home = \"/home/tomg/projects/penguins/data/colonies\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LUpSolJ-y8yC",
   "metadata": {
    "id": "LUpSolJ-y8yC"
   },
   "source": [
    "<br><br><br>\n",
    "## SECTION: Functions to find and organize data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de6d480",
   "metadata": {
    "id": "8de6d480"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Get a catalog of colony names...\n",
    "#\n",
    "\n",
    "def coloniesCatalog(proj_home=proj_home):\n",
    "        \n",
    "    # Find ALL of the colony names...\n",
    "    cols = [ name for name in os.listdir(proj_home) if os.path.isdir(os.path.join(proj_home, name)) ]\n",
    "\n",
    "    return cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "922e0cd5",
   "metadata": {
    "id": "922e0cd5"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Get a catalog of shapefiles...\n",
    "#\n",
    "\n",
    "def prjShpCatalog(proj_home=proj_home,name=''):\n",
    "\n",
    "    # Find all of the PROJECT shapefiles in \"proj_home\"...\n",
    "    files = glob.glob(proj_home+\"/**/*.shp\",recursive=True)\n",
    "    shps = [shp for shp in files if name.upper() in shp.upper()]\n",
    "    \n",
    "    return shps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f675c35",
   "metadata": {
    "id": "8f675c35"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Get a catalog of ALL satellite images...\n",
    "#   This finds all tif images on the mounted external drives.\n",
    "\n",
    "def imgCatalog(mount_dir=mount_dir):\n",
    "        \n",
    "    # Find ALL of the tif files...\n",
    "    imgs = glob.glob(mount_dir+\"/**/*.tif\",recursive=True)\n",
    "\n",
    "    return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4ef9ce9",
   "metadata": {
    "id": "d4ef9ce9"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Get a catalog of projects (colony and year combinations)...\n",
    "#\n",
    "\n",
    "def prjCatalog(proj_home=proj_home):\n",
    "    \n",
    "    prjs = []\n",
    "\n",
    "    dirs = glob.glob(proj_home+\"/**/*\",recursive=False)\n",
    "    prjs = [os.path.basename(p) for p in dirs]\n",
    "    return prjs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a09582",
   "metadata": {
    "id": "a8a09582"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Parse the project directory name, return a list\n",
    "#   [colony, year, month day, [catalog id list]]\n",
    "#\n",
    "\n",
    "def parse_project(prj):\n",
    "    \n",
    "    months = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "    month = ''\n",
    "    hasMonth = False\n",
    "    firstCatId = 2\n",
    "    \n",
    "    catid_list = []\n",
    "    \n",
    "    p_list = prj.split('_')\n",
    "    \n",
    "    # TO-DO Probably should check that the length of p_list is at least 3...\n",
    "    if not (len(p_list) >= 3):      #Prj needs at least colony, year, and catalog id.\n",
    "        return None\n",
    "\n",
    "    colony, year, unk = p_list[:3]\n",
    "    \n",
    "    # Some projects include month and day...\n",
    "    for m in months:\n",
    "        if m in unk:\n",
    "            # Found a month, so set it here\n",
    "            month = unk\n",
    "            hasMonth = True\n",
    "\n",
    "    # If project has a month, catalog ids start with index=3, else index=2...\n",
    "    if hasMonth:\n",
    "        firstCatId = 3\n",
    "\n",
    "    # Append catalog ids starting at the 4th positon...\n",
    "    \n",
    "    for c in p_list[firstCatId:]:\n",
    "        catid_list.append(c)\n",
    "    \n",
    "    return [colony, year, month, catid_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef8e1c4b",
   "metadata": {
    "id": "ef8e1c4b"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Given a search path, function returns a list of projects\n",
    "#   as a list: colony, year, catalog id, project directory\n",
    "\n",
    "def get_projects():\n",
    "    \n",
    "    projects = []\n",
    "    \n",
    "    for p in prjCatalog():\n",
    "        if not '.' in p:\n",
    "            projects.append([parse_project(p),p]) \n",
    "\n",
    "    return projects\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a8cfc34",
   "metadata": {
    "id": "5a8cfc34"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Get the bounds of the entire shapefile and buffer it by \"buffer\"...\n",
    "#   total_bounds returns coordinates in the image's coordinate system\n",
    "#   in this order: left, bottom, right, top\n",
    "#\n",
    "\n",
    "def get_bounds(shp, buffer=NONE):\n",
    "\n",
    "    b = gpd.read_file(shp).total_bounds\n",
    "\n",
    "    if buffer == NONE:\n",
    "        return b\n",
    "    \n",
    "    elif buffer == TILE16:  # Specific for 16x16 training thumbnails...\n",
    "        b[0] -= 18\n",
    "        b[1] -= 18\n",
    "        b[2] += 26\n",
    "        b[3] += 26\n",
    "        return b\n",
    "    \n",
    "    elif buffer == TILE32:  # Specific for 32x32 training thumbnails...\n",
    "        b[0] -= 36\n",
    "        b[1] -= 36\n",
    "        b[2] += 56\n",
    "        b[3] += 56\n",
    "        return b\n",
    "    \n",
    "    else:\n",
    "        b[0] -= buffer\n",
    "        b[1] -= buffer\n",
    "        b[2] += buffer\n",
    "        b[3] += buffer\n",
    "        return b\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c35c0e3",
   "metadata": {
    "id": "2c35c0e3"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# create a filename with path for the clipped file\n",
    "#\n",
    "\n",
    "def clipped_outfile(prj_name,path_name,img):\n",
    "\n",
    "    colony, year, month, (catalog_id) = prj_name\n",
    "    path = path_name\n",
    "    \n",
    "    cat_id = [c_id for c_id in catalog_id if c_id in img][0]\n",
    "\n",
    "    if month > '':\n",
    "        year += year + '_' + month\n",
    "        \n",
    "#    colony,yr,cat_id,path = project\n",
    "\n",
    "    return path + '/' + colony.lower() + year + '_' + cat_id + 'clipped.tif'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c093d3d",
   "metadata": {
    "id": "2c093d3d"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  This cell does the heavy lifting of clipping the original image and saving as a new image file\n",
    "#\n",
    "#   Inspiration: \n",
    "#     https://gis.stackexchange.com/questions/367832/using-rasterio-to-crop-image-using-pixel-coordinates-instead-of-geographic-coord\n",
    "#   Using \"from_bounds\" and \"windows\":\n",
    "#     https://rasterio.groups.io/g/main/topic/window_from_bounds_behaviour/69541972?p=,,,20,0,0,0::recentpostdate%2Fsticky,,,20,2,0,69541972\n",
    "#\n",
    "\n",
    "def clip_image(dst_file, img, shp, bounds):\n",
    "\n",
    "    left,bottom,right,top = bounds\n",
    "    \n",
    "    with rio.open(img) as src:\n",
    "\n",
    "        # Check that bounds all fit within this image...\n",
    "        if (src.bounds.left < left and src.bounds.bottom < bottom and\n",
    "            src.bounds.right > right and src.bounds.top > top):\n",
    "\n",
    "            # Create a window using from_bounds, with a 200m buffer...\n",
    "            window = rio.windows.from_bounds(left,bottom,right,top,src.transform)\n",
    "            # Use the transform of the source image...\n",
    "            transform = src.window_transform(window)\n",
    "\n",
    "            # Start with the profile from the source image...\n",
    "            profile = src.profile\n",
    "            # Update the profile of the window with the new height, width...\n",
    "            profile.update({\n",
    "                'height':    int(window.height),\n",
    "                'width':     int(window.width),\n",
    "                'transform': transform })\n",
    "\n",
    "            # Read the source using the new window, and write the output file...\n",
    "            print('Writing file {}'.format(dst_file))\n",
    "            print('Bounds - {}'.format(bounds))\n",
    "            with rio.open(dst_file,'w',**profile) as dst:\n",
    "                dst.write(src.read(window=window))\n",
    "            return True\n",
    "        \n",
    "        print('Bounding box of shapefile {} not in \\nimage file: {}.\\n'.format(shp,img))\n",
    "        return False\n",
    "    \n",
    "    for c_id in catalog_id:\n",
    "        if c_id in img:\n",
    "            cat_id = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1519894b",
   "metadata": {
    "id": "1519894b"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Match projects to existing shapefiles and images on catalog id...\n",
    "#\n",
    "\n",
    "def create_prj_list(projects, shps, imgs):\n",
    "\n",
    "    prj_list = []\n",
    "\n",
    "    for p in projects:\n",
    "        colony, year, month, (catalog_id) = p[0]\n",
    "        prj_path = p[1]\n",
    "        \n",
    "        # Look for path names that match the catalog id and contain shapefiles...\n",
    "        shp_list = []\n",
    "        for s in shps:\n",
    "            if prj_path in s:\n",
    "                shp_list.append(s)\n",
    "\n",
    "        # Now look for images matching the catalog id...\n",
    "        img_list = []\n",
    "        name_list = []\n",
    "\n",
    "        for cat_id in catalog_id:\n",
    "            for i in imgs:\n",
    "                if ((cat_id in i) and (\".tif\" in i) and not (\"clipped\" in i)) \\\n",
    "                        and (os.path.basename(i) not in name_list):\n",
    "                    img_list.append(i)\n",
    "                    name_list.append(os.path.basename(i))\n",
    "\n",
    "        prj_list.append([p, shp_list, img_list])\n",
    "\n",
    "    return prj_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0QTfXyRB2BkA",
   "metadata": {
    "id": "0QTfXyRB2BkA"
   },
   "source": [
    "<br><br><br>\n",
    "## SECTION: Create the data structures\n",
    "\n",
    "This section reads project data and creates the required data structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y5k1zKvI2tDZ",
   "metadata": {
    "id": "y5k1zKvI2tDZ"
   },
   "source": [
    "### Find projects, shapefiles and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40ee122b",
   "metadata": {
    "id": "40ee122b",
    "outputId": "14863e7a-4a88-450a-d9be-48f01a02109d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found shapefiles - 561, images - 18237\n",
      "CPU times: user 610 ms, sys: 542 ms, total: 1.15 s\n",
      "Wall time: 2.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#\n",
    "# Create the required lists\n",
    "#\n",
    "\n",
    "# Get the projects, shapefile list and image list...\n",
    "projects = get_projects()\n",
    "shps_cat = prjShpCatalog()\n",
    "imgs_cat = imgCatalog()\n",
    "\n",
    "print('Found shapefiles - {}, images - {}'.format(len(shps_cat), len(imgs_cat)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01bbdf6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Create a project list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfbb2dfd",
   "metadata": {
    "id": "dfbb2dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222 projects\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Combine the lists by colony, project, shapefile, images\n",
    "#\n",
    "\n",
    "# Create a project list data structure from the lists...\n",
    "prj_list = create_prj_list(projects, shps_cat, imgs_cat)\n",
    "\n",
    "print('Found {} projects'.format(len(prj_list)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ANUjt4n3vm5",
   "metadata": {
    "id": "9ANUjt4n3vm5"
   },
   "source": [
    "<br><br><br>\n",
    "## SECTION - Create the needed data objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vuECXoMz5EDR",
   "metadata": {
    "id": "vuECXoMz5EDR"
   },
   "source": [
    "### Create clipped images\n",
    "For each colony and study season, clip the satellite image used for classification to the bounding box of identified penguins. Various buffers can be applied depending on the purpose (tile size, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05a668",
   "metadata": {
    "id": "ba05a668",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#\n",
    "# Create clipped images from original satellite imagery. Use classification shapefile and buffer.\n",
    "#   (This takes a while...)\n",
    "#\n",
    "\n",
    "# Loop through the project list\n",
    "for p in prj_list:\n",
    "\n",
    "    prj,shps,imgs = p\n",
    "    prj_name, path_name = prj\n",
    "    colony,yr,month,(cat_id) = prj_name\n",
    "\n",
    "    print(\"\\nProcessing {} {} {}\".format(colony,yr,cat_id))\n",
    "    \n",
    "    # Look for classification shapefile...\n",
    "    for s in shps:\n",
    "        if \"CLASS\" in os.path.basename(s.upper()):\n",
    "            print(\"found {}\\n\".format(s))\n",
    "            # Get the directory path to use for the clipped file...\n",
    "            path = os.path.dirname(s)\n",
    "            \n",
    "            # Get the bounding box of the shapefile (left,bottom,right,top...)\n",
    "            \n",
    "            #   Set the type of bounds buffer:\n",
    "            #     One of NONE, TILE16, TILE32, or an integer > 2. The TILE16 and TILE32 types are\n",
    "            #       asymetrical buffer expecially training images.\n",
    "            b = get_bounds(s,TILE32)\n",
    "\n",
    "            # Process list of matching images...\n",
    "            for i in imgs:\n",
    "                # Progress report...\n",
    "                print(\"checking image {}\\n\".format(i))\n",
    "                # Create a output file name...\n",
    "                #   Put clipped image file in project directory...\n",
    "                outfile = clipped_outfile(prj_name,path,i)\n",
    "\n",
    "                # Actually clip and save the file...\n",
    "                if clip_image(outfile,i,s,b):  # outfile name, image path, shapefile, bounds\n",
    "                    break                      # found the right image, stop looking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "URpuRCT_8rTV",
   "metadata": {
    "id": "URpuRCT_8rTV"
   },
   "source": [
    "<br>\n",
    "\n",
    "### Create colony bounding box shapefile\n",
    "Using the bounding box of all  the clipped images, create a bounding box for each penguin colony. Write all colony bounding boxes to a single shapefile. \n",
    "\n",
    "##### ***Requires study bounding boxes, above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50c755c1",
   "metadata": {
    "id": "50c755c1"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Find the bounding box of all of the clipped images for a colony...\n",
    "#   Match colonies to existing clipped images...\n",
    "#\n",
    "\n",
    "# Find all of the colonies \"proj_home\"...\n",
    "colonies = coloniesCatalog()\n",
    "bnds = []\n",
    "\n",
    "for colony in colonies:\n",
    "\n",
    "    # Find all of the clipped images for current colony...\n",
    "    path = proj_home+\"/\"+colony+\"/**/*clipped.tif\"\n",
    "    files = glob.glob(path,recursive=True)\n",
    "    \n",
    "    # Check that there is at least one clipped image file...\n",
    "    if len(files) > 0:\n",
    "        first = True\n",
    "        for file in files:\n",
    "            with rio.open(file) as src:\n",
    "\n",
    "                if first:\n",
    "                    left = src.bounds.left\n",
    "                    bottom = src.bounds.bottom\n",
    "                    right = src.bounds.right\n",
    "                    top = src.bounds.top\n",
    "\n",
    "                    first = False\n",
    "\n",
    "                else:\n",
    "                    left = min(left,src.bounds.left)\n",
    "                    bottom = min(bottom,src.bounds.bottom)\n",
    "                    right = max(right,src.bounds.right)\n",
    "                    top = max(top,src.bounds.top)\n",
    "\n",
    "                    \n",
    "        # Buffer bounds...\n",
    "        buffer = 0.\n",
    "\n",
    "        left -= buffer\n",
    "        bottom -= buffer\n",
    "        right += buffer\n",
    "        top += buffer\n",
    "                    \n",
    "        geom = 'POLYGON(('+str(left)+' '+str(top)+', '+str(right)+' '+str(top)+', ' \\\n",
    "            +str(right)+' '+str(bottom)+', '+str(left)+' '+str(bottom)+', '+str(left)+' '+str(top)+'))'            \n",
    "\n",
    "        bnds.append([colony,geom])\n",
    "\n",
    "    # Convert list to geodataframe...\n",
    "    gdf = gpd.GeoDataFrame(bnds)\n",
    "    gdf.columns=['colony','wkt']\n",
    "    gdf['geometry']=gpd.GeoSeries.from_wkt(gdf['wkt'])\n",
    "\n",
    "    # Drop the 'wkt' column...\n",
    "    gdf.drop(columns='wkt',inplace=True)\n",
    "\n",
    "    # Write shapefile...\n",
    "    gdf.to_file(proj_home+\"/colony_boundaries.shp\",crs=\"EPSG:3031\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cR0XkHA9vc",
   "metadata": {
    "id": "84cR0XkHA9vc"
   },
   "source": [
    "<br>\n",
    "\n",
    "### Create colony bounding box in KML format\n",
    "Using the bounding box of all  the clipped images, create a single bounding box KML file for the penguin colony.\n",
    "##### ***Requires study bounding boxes, above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f62a501c",
   "metadata": {
    "id": "f62a501c"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Create a kml file for each colony...\n",
    "#\n",
    "\n",
    "for index,row in gdf.iterrows():\n",
    "    shp_path = proj_home+\"/\"+row['colony']+\"/\"+row['colony']+\"_extent.kml\"\n",
    "\n",
    "    gdf[index:index+1].to_file(shp_path,driver=\"KML\",crs=\"EPSG:3031\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X5z0zO84C0_i",
   "metadata": {
    "id": "X5z0zO84C0_i"
   },
   "source": [
    "<br>\n",
    "\n",
    "### Create classified tiles\n",
    "Create penguin and no_penguin tiles from the clipped images. \n",
    "##### ***Requires clipped images, above.\n",
    "\n",
    "Note: This takes about 5 hours to run on an old desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e5148a",
   "metadata": {
    "id": "e3e5148a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#\n",
    "# Tile individual images from each project clipped image...\n",
    "#\n",
    "\n",
    "from shapely.geometry import box, polygon\n",
    "from rasterio.windows import Window\n",
    "\n",
    "# Set the tile size for this step...\n",
    "tile_size = 32\n",
    "\n",
    "# Loop through the project list\n",
    "for p in prj_list:\n",
    "\n",
    "    prj,shps,imgs = p\n",
    "    prj_name, path_name = prj\n",
    "    colony,yr,month,(cat_id) = prj_name\n",
    "    \n",
    "    # Look for classification shapefile. Use either the classified point shapefile or the \n",
    "    #   penguin polygon shapefile...\n",
    "    for s in shps:\n",
    "        if os.path.basename(s.upper()).startswith(\"POLY\"):\n",
    "\n",
    "#    Penguins shapefile contains all four classifications. The PolyPen \n",
    "#      shapefile contains only penguins. For now, use PolyPen\n",
    "#        if os.path.basename(s.upper()).startswith(\"PEN\") or \\\n",
    "#              os.path.basename(s.upper()).startswith(\"POLY\"):\n",
    "\n",
    "            print(\"found shapefile - {}\".format(s))\n",
    "\n",
    "            # Look for the corresponding clipped tif file...\n",
    "            #   Just look for a clipped.tif file in the directory we just found...\n",
    "            path = os.path.dirname(s)\n",
    "            file = glob.glob(path+\"/*clipped.tif\")  # There is only one!\n",
    "            if file:\n",
    "                print(\"found img file - {}, tiling...\\n\".format(file[0]))\n",
    "\n",
    "                # Read the penguins polygons into a gdf...\n",
    "                gdf = gpd.read_file(s)\n",
    "                penguins = gdf.loc[gdf.gridcode==1]\n",
    "                \n",
    "                # Read the clipped file\n",
    "                with rio.open(file[0]) as src:\n",
    "                    \n",
    "                    cols = src.width\n",
    "                    rows = src.height\n",
    "                    \n",
    "                    print(cols,rows)\n",
    "                    for r in range(0,cols-tile_size,tile_size):\n",
    "                        for c in range(0,rows-tile_size,tile_size):\n",
    "                    \n",
    "                            # Create a window using offsets and size...\n",
    "                            window = Window(r,c,width=tile_size,height=tile_size)\n",
    "                            \n",
    "                            transform = src.window_transform(window)\n",
    "                            profile = src.profile\n",
    "                            profile.update({\n",
    "                                'height': window.height,\n",
    "                                'width': window.width,\n",
    "                                'transform': transform })\n",
    "                            \n",
    "                            with rio.open('/tmp/tmp_file.tif','w',**profile) as dst:\n",
    "\n",
    "                                tile_bounds = dst.bounds\n",
    "                                geom = box(*tile_bounds)\n",
    "                                dst.close()\n",
    "                               \n",
    "                                if penguins.intersects(geom).any():\n",
    "                                    dst_file = '/home/tomg/projects/penguins/models/train/penguins/'+path_name+'_{:04d}'.format(r)+'{:04d}'.format(c)+'.tif'\n",
    "                                    with rio.open(dst_file,'w',**profile) as dst:\n",
    "                                        dst.write(src.read(window=window))\n",
    "                                        dst.close()\n",
    "                                    \n",
    "                                else:\n",
    "                                    dst_file = '/home/tomg/projects/penguins/models/train/nopenguins/'+path_name+'_{:04d}'.format(r)+'{:04d}'.format(c)+'.tif'\n",
    "                                    with rio.open(dst_file,'w',**profile) as dst:\n",
    "                                        dst.write(src.read(window=window))\n",
    "                                        dst.close()\n",
    "\n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee2a3c",
   "metadata": {
    "id": "b8261238"
   },
   "source": [
    "<br><br><br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Penguin_data_preparation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
